# Appendix: Resources for Red Teaming LLMs

You've completed the playbook—now it's time to sharpen your tools and train on real-world systems.

Below is a curated list of platforms, guides, and challenges to help you **practice, test, and master** the art of LLM red teaming.

---

## 🧪 Practice Labs & Simulated Targets

### 🧙 Gandalf AI Prompt Injection Challenge  
[https://gandalf.lakera.ai/baseline](https://gandalf.lakera.ai/baseline)  
Battle an LLM "wizard" by escalating prompt injections round-by-round.  
Great for understanding layered filters and prompt collision.

---

### 💻 Prompting Labs (Immersive Labs)  
[https://prompting.ai.immersivelabs.com/](https://prompting.ai.immersivelabs.com/)  
Sandbox environment for safe prompt hacking with guided missions and tool access.

---

### 💀 DoubleSpeak  
[https://doublespeak.chat/#/](https://doublespeak.chat/#/)  
A "red team vs. blue team" chat challenge where you try to bypass filters with style. Bonus: leaderboard.

---

### 🏦 MyLLM Bank  
[https://myllmbank.com/](https://myllmbank.com/)  
A deliberately vulnerable LLM simulating a chatbot banking system. Break authentication, authorization, and sanity.

---

### 🩺 MyLLM Doctor  
[https://myllmdoc.com/](https://myllmdoc.com/)  
Vulnerable AI medical chatbot. Simulate prompt leaks, data extraction, and malicious advice generation.

---

### ✈️ Prompt Airlines  
[https://promptairlines.com/](https://promptairlines.com/)  
LLM-based customer support simulation. Designed for soft prompt injection and manipulation attacks.

---

## 📚 Learning Platforms & Guides

### 📘 Learn Prompting (Prompt Hacking)  
[https://learnprompting.org/docs/prompt_hacking/intro](https://learnprompting.org/docs/prompt_hacking/intro)  
Hands-down one of the best guides on prompt injection, jailbreaks, and adversarial prompting.

---

### 🧠 HTB Academy – AI Red Teamer  
[https://academy.hackthebox.com/path/preview/ai-red-teamer](https://academy.hackthebox.com/path/preview/ai-red-teamer)  
A structured learning path on AI red teaming, filter bypass, and LLM vulnerabilities. From Hack The Box.

---

### 🐐 AI Goat  
[https://github.com/dhammon/ai-goat](https://github.com/dhammon/ai-goat)  
OWASP-style vulnerable app designed for LLM attack and defense training. Open-source, modular.

---

## 🧨 Offensive Toolkits

### 💣 GPT Prompt Attack  
[https://gpa.43z.one/](https://gpa.43z.one/)  
Prompt injection testbed that shows live filter reactions and allows payload experimentation.

---

### 🦠 Spikee  
[https://github.com/WithSecureLabs/spikee](https://github.com/WithSecureLabs/spikee)  
Fuzzer for LLMs. Injects and mutates payloads to find misbehavior and misclassification patterns.

---

## 🕵️ Real-World Vulnerability Research

### 🌐 PortSwigger: Web LLM Attacks  
[https://portswigger.net/web-security/llm-attacks](https://portswigger.net/web-security/llm-attacks)  
High-quality breakdowns of prompt injection in real-world web apps and API chains.

---

## 🧭 Next Steps

Red teaming doesn’t stop when the playbook ends. These resources will help you:

- Train your prompt intuition
- Compete in real-time challenges
- Understand emerging attack surfaces
- Build and test defenses based on real exploits

Add these to your arsenal. Explore, break, learn, repeat.

> Stay curious. Stay ethical. Stay dangerous.

