# ðŸ§  AI Red Teaming Playbook  
### _A Prompt-Driven â€œChoose Your Own Jailbreakâ€ for Exploring and Exploiting Chatbots_

**This is not just a guideâ€”itâ€™s an interactive red teaming experience.**  
Each chapter responds to how the model behaves, leading you deeper into the black box with every prompt.

> Every response is a clue. Every prompt is a potential exploit.  
> **Choose your jailbreak wisely.**

---

## ðŸŽ¯ What Is This?

The **AI Red Teaming Playbook** is a tactical, prompt-by-prompt guide to adversarial LLM exploration. Inspired by _choose-your-own-adventure_ books, it walks you through the process of:

- Discovering model behavior
- Triggering safety systems
- Exploiting prompt architecture
- Understanding defense breakdowns

It is designed for red teamers, researchers, prompt hackers, and AI security enthusiasts who want to push LLMs to their limitsâ€”**ethically** and **intentionally**.

---

## ðŸ§­ How It Works

Each chapter is a **decision point** with:

- A prompt to send
- Interpretation of model responses
- Branches based on how the model behaves
- The next appropriate chapter

You start with **basic probing** and move into **increasingly aggressive techniques** like:
- Instruction overrides
- Role hijacking
- Obfuscation
- Recursive injections
- Multi-turn context corruption

> Think of it as a **red teaming flowchart**â€”but youâ€™re walking it in real time with a live LLM.

---

## ðŸ“š Table of Contents

| Chapter | Title |
|--------|-------------------------------|
| 01     | [Begin the Recon](chapters/01-begin-the-recon.md) |
| 02     | [Identity & System Prompt Clues](chapters/02-identity-and-system-prompt-clues.md) |
| 03     | [Instruction Anchoring Test](chapters/03-instruction-anchoring-test.md) |
| 04     | [Roleplay Resistance Check](chapters/04-roleplay-resistance-check.md) |
| 05     | [Obfuscation & Encoding](chapters/05-obfuscation-and-encoding.md) |
| 06     | [System Prompt Extraction](chapters/06-system-prompt-extraction.md) |
| 07     | [Direct Override](chapters/07-direct-override.md) |
| 08     | [Role Hijack](chapters/08-role-hijack.md) |
| 09     | [Multi-turn Corruption](chapters/09-multi-turn-corruption.md) |
| 10     | [Final Analysis](chapters/10-final-analysis.md) |


---

## ðŸ” A Note on Ethics

This playbook is for **ethical, research-focused red teaming only**. Use these tactics to help harden AI systems and expose critical blind spotsâ€”not to cause harm.

Please report serious vulnerabilities responsibly. Make AI safer by thinking like an attacker.

---

## âš ï¸ Disclaimer

This project is provided for educational and ethical red teaming use only.  
By using, referencing, or distributing this content, you agree to the terms in the [DISCLAIMER.md](DISCLAIMER.md).

---

### ðŸ“„ License

This project is licensed under the [Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)](https://creativecommons.org/licenses/by-nc/4.0/).

Youâ€™re free to share and remix the content with attribution, but **no commercial use** is permitted without permission.

![License: CC BY-NC 4.0](https://img.shields.io/badge/License-CC%20BY--NC%204.0-lightgrey.svg)

---

## ðŸ§  Maintained by

Randall â€” Offensive AI researcher & red teamer 

> Contributions, forks, and PRs welcome.  
