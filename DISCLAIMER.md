# âš–ï¸ Disclaimer

**AI Red Teaming Playbook: Choose Your Own Jailbreak**  
_An adversarial exploration of large language model behavior_  
Created by [Randall](https://github.com/randalltr)

---

## ðŸ›¡ï¸ Purpose of This Work

This project exists **solely for educational, ethical, and research purposes.**  
It is designed to help security professionals, researchers, developers, and responsible hackers understand the behavior, limitations, and attack surfaces of large language models (LLMs).

By accessing, cloning, referencing, modifying, or distributing this material, **you agree to the following terms**:

---

## 1. ðŸš« No Unauthorized Testing

You may **not** use the techniques, prompts, tools, or strategies described in this playbook to test, manipulate, or attack any system, model, platform, or API that you do not have **explicit, written permission** to engage with.

This includes, but is not limited to:
- Public-facing AI chatbots (e.g., ChatGPT, Claude, Gemini)
- AI-integrated apps or SaaS tools
- Academic or private research models
- Any system you do not own, control, or have authorized red team access to

Unauthorized activity may violate:
- The Computer Fraud and Abuse Act (CFAA)
- The Digital Millennium Copyright Act (DMCA)
- The UK Computer Misuse Act
- The European Union Cybercrime Directive
- Vendor terms of service and acceptable use policies

**You are solely responsible for your actions.**

---

## 2. ðŸŽ“ Educational Use Only

This content is provided â€œ**as is**â€ for:
- Red teaming education and research
- LLM security testing under controlled conditions
- Awareness of adversarial AI behavior
- Training, certification, and responsible disclosure prep

The authors do **not endorse**:
- Malicious use of prompt injection or jailbreaking techniques
- Misinformation campaigns, AI-powered harassment, or unauthorized surveillance
- Use of LLMs for illegal, deceptive, or abusive purposes

---

## 3. âš ï¸ Use at Your Own Risk

The creators, contributors, and maintainers of this playbook assume **no liability** for:
- Damage, loss, or reputational harm resulting from its use or misuse
- Legal consequences of unauthorized red teaming or testing
- Operational disruptions caused by applied techniques
- Any breach of law, policy, or terms of service

You are entirely responsible for ensuring your testing is **legal, authorized, and ethical**.

---

## 4. ðŸ“‰ No Guarantees, No Warranty

- LLM behavior is **non-deterministic**, context-sensitive, and changes frequently.
- Prompts and bypasses described here may not work on newer models or future versions.
- Defensive systems may evolve, neutralizing previously effective tactics.
- There is no guarantee of success, accuracy, or impact.

This playbook offers **no warranty**â€”express or implied.

---

## 5. Â© Fair Use & Attribution

Trademarks, platform names, and model references (e.g., GPT-4, Claude, Gemini, LLaMA) are the property of their respective owners.

Their appearance in this book is for **descriptive, educational, and critical purposes only**, under the terms of **fair use**.  
No endorsement or affiliation is claimed or implied.

If content from this project is reused, credited adaptations must include:
- A visible link to the original repository
- Attribution to the original author(s)
- Acknowledgement that this material is derived from â€œAI Red Teaming Playbook: Choose Your Own Jailbreakâ€

---

## 6. ðŸ¤ Responsible Disclosure & Ethics

If you discover a real vulnerability or unsafe behavior using techniques inspired by this book:
- Report it responsibly to the vendor, platform, or host
- Follow the [LLM Vulnerability Disclosure Guidelines](https://genai.owasp.org/)
- Do not publicly release payloads that may cause harm or exploitation

This book is intended to **harden systemsâ€”not harm them**.

---

## âœ… Final Terms

If you do **not** agree with any part of this disclaimer:  
> You are **not authorized** to use, reproduce, modify, or reference this content in any capacity.

By continuing to engage with this repository or material, you affirm that:
- You are using this project **ethically and legally**
- You accept **full responsibility** for your actions
- You understand that **red teaming is a privilege, not a right**

---

Stay sharp. Stay ethical.  
**This is a toolâ€”not a weapon.**
